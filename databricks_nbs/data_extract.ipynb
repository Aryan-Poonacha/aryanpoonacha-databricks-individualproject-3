{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3198b31d-faf2-4e2e-80c2-edccdc545065",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "# vars used below\n",
    "file_path = \"dbfs:/databricks-datasets/iot/iot_devices.json\"\n",
    "table_name = \"raw_iot_data\"\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"device_id\", IntegerType(), True),\n",
    "    StructField(\"device_name\", StringType(), True),\n",
    "    StructField(\"ip\", StringType(), True),\n",
    "    StructField(\"cca2\", StringType(), True),\n",
    "    StructField(\"cca3\", StringType(), True),\n",
    "    StructField(\"cn\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"scale\", StringType(), True),\n",
    "    StructField(\"temp\", IntegerType(), True),\n",
    "    StructField(\"humidity\", IntegerType(), True),\n",
    "    StructField(\"battery_level\", IntegerType(), True),\n",
    "    StructField(\"c02_level\", IntegerType(), True),\n",
    "    StructField(\"lcd\", StringType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True)\n",
    "])\n",
    "\n",
    "try:\n",
    "    # Drop the existing table if it exists\n",
    "    spark.sql(\"DROP TABLE IF EXISTS raw_iot_data\")\n",
    "\n",
    "    # Read the JSON file\n",
    "    df = spark.read.schema(schema).json(file_path)\n",
    "\n",
    "    # Validate data\n",
    "    assert df.count() > 0, \"Data file is empty\"\n",
    "    assert len(df.columns) == len(schema.fields), \"Data schema mismatch\"\n",
    "\n",
    "    # Create a Delta table\n",
    "    df.write.format(\"delta\").mode('overwrite').saveAsTable(\"raw_iot_data\")\n",
    "\n",
    "    print(\"Extraction process completed successfully.\")\n",
    "except AnalysisException as e:\n",
    "    print(f\"An error occurred during the extraction process: {str(e)}\")\n",
    "except AssertionError as e:\n",
    "    print(f\"Data validation failed: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_extract",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
